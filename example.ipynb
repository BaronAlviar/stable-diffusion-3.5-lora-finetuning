{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6b2ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/gokhaneraslan/stable-diffusion-3.5-lora-finetuning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40efde4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r /content/stable-diffusion-3.5-lora-finetuning/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00afd4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login --token your_hugginface_token --add-to-git-credential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4958b4ef",
   "metadata": {},
   "source": [
    "In which compute environment are you running?\n",
    "[0] This machine\n",
    "[1] AWS (Amazon SageMaker)\n",
    "-> 0 (This machine)\n",
    "\n",
    "Which type of machine are you using?\n",
    "[0] No distributed training\n",
    "[1] multi-CPU\n",
    "[2] multi-GPU\n",
    "...\n",
    "-> 0 (No distributed training, if you are on a single GPU)\n",
    "\n",
    "Do you want to run your training on CPU only? [yes/NO]:\n",
    "-> NO\n",
    "\n",
    "Do you wish to optimize your script with torch dynamo? [yes/NO]:\n",
    "-> NO\n",
    "\n",
    "Do you want to use DeepSpeed? [yes/NO]:\n",
    "-> NO\n",
    "\n",
    "What GPU(s) (by id) should be used for training on this machine? (e.g. '0,1,2,3', 'all') [all]:\n",
    "-> all (or 0)\n",
    "\n",
    "Would you like to enable numa efficiency? [yes/NO]:\n",
    "-> NO (This is safe for most systems)\n",
    "\n",
    "Do you wish to use mixed precision?\n",
    "[0] no\n",
    "[1] fp16\n",
    "[2] bf16\n",
    "...\n",
    "-> 2 (bf16, to match our project's config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef50ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da6e44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U datasets # To avoid any problems while loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b3d70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# You can download a dataset from huggingface for testing and try it out.\n",
    "\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def download_dataset(save_path):\n",
    "    dataset = load_dataset(\"moving-j/ghibli-style-100\")\n",
    "\n",
    "    save_path = Path(save_path)\n",
    "    images_dir = save_path / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata = []\n",
    "    for i, item in enumerate(dataset['train']):\n",
    "        # Save image\n",
    "        image_path = f\"test{i:03d}.png\"\n",
    "        item['image'].save(images_dir / image_path)\n",
    "\n",
    "        # Prepare metadata\n",
    "        metadata.append({\n",
    "            \"file_name\": image_path,\n",
    "            \"text\": item['text']\n",
    "        })\n",
    "\n",
    "    # create metadata.jsonl\n",
    "    with open(save_path / \"metadata.jsonl\", 'w') as f:\n",
    "        for entry in metadata:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "\n",
    "download_dataset(\"/content/MyImgDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be3f6b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!accelerate launch /content/stable-diffusion-3.5-lora-finetuning/train.py --config_path /content/stable-diffusion-3.5-lora-finetuning/configs/training_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c66d27",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/MyImgDataset/lora_fine_tuning/inference.py \\\n",
    "    --base_model_id \"stabilityai/stable-diffusion-3.5-medium\" \\\n",
    "    --lora_checkpoint_dir \"/content/stable-diffusion-3.5-lora-finetuning/sd3_lora_output/final\" \\\n",
    "    --prompt \"anime style, a girl with blue hair in a magical forest, detailed, beautiful lighting\" \\\n",
    "    --steps 28 \\\n",
    "    --guidance_scale 7.0 \\\n",
    "    --resolution 512 \\\n",
    "    --device \"cuda\" \\\n",
    "    --output_path \"/content/anime_style_girl.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16552092",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"/content/gaya_style_girl.png\")\n",
    "\n",
    "display(image)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
